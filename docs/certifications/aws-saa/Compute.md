---
title: コンピューティング
---

## Amazon EC2（Amazon Elastic Compute Cloud）

### 1. サービス概要

Amazon EC2（Amazon Elastic Compute Cloud）は、AWS が提供するスケーラブルな仮想サーバー（インスタンス）をオンデマンドで起動・停止できるクラウドコンピューティングサービスである。  
ユーザーはハードウェア管理から解放され、数分で仮想マシンを立ち上げ、必要に応じてスケールアウトやスケールインを柔軟に行うことができる。

主なユースケースとして、

- Web サーバー
- アプリケーションサーバー
- バッチ処理
- 開発・テスト環境
- ビッグデータ分析
- HPC（高性能コンピューティング）

などが挙げられる。

### 2. 主な特徴と機能

#### 2.1 インスタンスタイプとファミリー

CPU、メモリ、ストレージ、ネットワーク性能を組み合わせた多種多様なインスタンスタイプが用意されている。  
汎用（M シリーズ）、コンピュート最適化（C シリーズ）、メモリ最適化（R シリーズ）、ストレージ最適化（I・D シリーズ）など、ワークロードに合わせて選択可能である。

#### 2.2 ストレージオプション

Amazon EBS（Elastic Block Store）を利用したブロックストレージや、インスタンスストア（一時的ローカルストレージ）が利用可能である。  
永続的ストレージには EBS、オブジェクトストレージには Amazon S3 を組み合わせるのが一般的である。

#### 2.3 ネットワーキングと VPC

EC2 インスタンスは Amazon VPC（Virtual Private Cloud）内で起動され、プライベート IP、パブリック IP、セキュリティグループ、ネットワーク ACL でアクセス制御が可能。  
Elastic IP で固定パブリック IP を割り当てたり、ENI（Elastic Network Interface）で複数ネットワークインターフェースを付与できる。

#### 2.4 スケーリングと自動化

Auto Scaling グループを組み合わせることで、負荷に応じて EC2 インスタンス数を自動的に増減できる。  
AWS Systems Manager や EC2 インスタンスメタデータを活用して構成管理、CloudWatch によるモニタリング、EventBridge や Lambda との連携で自動運用が可能である。

### 3. アーキテクチャおよび技術要素

1. ユーザーは AWS Management Console、CLI、SDK を用いて EC2 インスタンスを起動。
2. インスタンスは指定した AMI（Amazon Machine Image）から立ち上がり、特定の VPC サブネット内に配置。
3. 指定したインスタンスタイプ、キーペア、セキュリティグループ、IAM ロールなどを通じて環境構成。
4. EC2 はオンデマンド、リザーブド、スポットなど柔軟な料金モデルで利用可能。

### 4. セキュリティと認証・認可

- **IAM ロール**: EC2 インスタンスに IAM ロールを割り当てることで、インスタンス上のアプリケーションが AWS リソースに安全にアクセス。
- **セキュリティグループ**: インバウンド/アウトバウンドトラフィックをステートフルに制御。
- **キーペア**: SSH ログイン用に公開鍵/秘密鍵方式を使用。秘密鍵はユーザー側で安全管理。
- **VPC とサブネット設計**: パブリックサブネット、プライベートサブネットを分けて、必要な範囲でのみインターネットアクセスを許可。

### 5. 料金形態

EC2 の料金は、使用時間、インスタンスタイプ、使用するライセンス、OS、ネットワーク帯域、EBS 使用量などで変動する。

- **オンデマンド**: 利用時間単位の課金。
- **リザーブドインスタンス**: 1 年または 3 年のコミットで割引適用。
- **スポットインスタンス**: 遊休キャパシティを活用した低価格モデル（ただし中断される可能性あり）。

### 6. よくあるアーキテクチャ・設計パターン

- **Web/App サーバー**: Auto Scaling + ELB + EC2 で高可用性 Web アプリ構成。
- **バッチ処理**: スポットインスタンスでコスト削減、S3 に格納したデータを定期処理。
- **HPC クラスター**: コンピュート最適化インスタンスで大規模並列計算。
- **開発・テスト環境**: 短期間で立ち上げ、不要になれば停止/削除。

### 7. 設定・デプロイ手順（ハンズオン例）

1. EC2 コンソールで"Launch Instance"をクリック。
2. AMI、インスタンスタイプ、VPC サブネット、セキュリティグループ、キーペアを選択。
3. 起動後、パブリック IP または Elastic IP を用いて SSH 接続。
4. 必要に応じて CloudWatch メトリクスで監視、Auto Scaling ルール設定。
5. 不要になればインスタンスを Terminate してコスト削減。

### 8. 試験で問われやすいポイント

#### 8.1 インスタンスタイプ選択

- ワークロード特性（CPU 集約か、メモリ集約か、ストレージ I/O か）に基づく最適なタイプ選択。

#### 8.2 セキュリティグループと ACL

- セキュリティグループはステートフル、ネットワーク ACL はステートレス。

#### 8.3 IAM ロールとキーペア管理

- IAM ロールで EC2 から S3 や DynamoDB などに安全にアクセス。
- SSH ログイン用キーペアは事前に準備し、秘密鍵はローカルで安全保管。

#### 8.4 Auto Scaling とロードバランシング

- Auto Scaling と ELB を組み合わせて高可用性とスケーラビリティを実現。

#### 8.5 EBS とインスタンスストア

- EBS は永続ストレージ、インスタンス停止・再起動間でデータ保持。
- インスタンスストアは一時的ストレージでインスタンス終了で消失。

#### 8.6 価格モデル理解

- オンデマンドは柔軟、リザーブドは長期割引、スポットは安価だが中断リスクあり。

#### 8.7 AMI 管理

- 独自 AMI 作成で構成済み環境を迅速に再現。

#### 8.8 試験で頻出となる具体的な問われ方と答え

- Q: インスタンスに割り当てた IAM ロールはどのように使われるか？
  - A: インスタンス内のアプリケーションが AWS CLI や SDK を通じて IAM 認証情報無しで AWS サービスにアクセス可能
- Q: セキュリティグループとネットワーク ACL の違いは？
  - A: セキュリティグループはステートフルでインスタンスレベル、ネットワーク ACL はステートレスでサブネットレベル
- Q: スポットインスタンスの特徴は？
  - A: 安価だが AWS が必要に応じてインスタンスを中断する可能性がある
- Q: EBS とインスタンスストアの違いは？
  - A: EBS は永続ストレージ、インスタンスストアは一時的でインスタンス終了でデータ消失
- Q: Auto Scaling の利点は？
  - A: 負荷変動に応じて自動的にインスタンス数を増減し、コスト最適化と可用性向上を実現

---

## Amazon EC2 Auto Scaling

### 1. サービス概要

Amazon EC2 Auto Scaling は、AWS が提供するサービスで、需要に応じて Amazon EC2 インスタンスを自動的に起動・停止することで、アプリケーションの可用性、耐障害性、コスト効率を向上させる。  
これにより、トラフィックの変動に合わせてリソースを動的に調整し、常に最適なパフォーマンスを維持できる。  
Auto Scaling は、単一の EC2 インスタンスだけでなく、EC2 インスタンスのグループを管理できる。

主なユースケースとして、

- ウェブアプリケーションのスケーリング
- バッチ処理のスケーリング
- 負荷テスト
- 災害復旧

などが挙げられる。

### 2. 主な特徴と機能

#### 2.1 動的なスケーリング

EC2 Auto Scaling は、トラフィックの変動に応じて自動的に EC2 インスタンスの数を調整できる。  
需要の増加時にはインスタンスを増やし、需要の減少時にはインスタンスを減らすことで、リソースの効率的な利用とコスト削減を実現する。

#### 2.2 スケーリングポリシー

Auto Scaling は、様々なスケーリングポリシーをサポートしており、アプリケーションの特性に合わせて最適なスケーリング戦略を定義できる。  
以下のようなスケーリングポリシーを利用できる。

- **ターゲット追跡スケーリング**: CPU 使用率や Application Load Balancer のメトリクスなどのターゲット値を指定し、自動的にインスタンス数を調整。
- **ステップスケーリング**: CloudWatch アラームに基づいて、指定されたステップ数でインスタンス数を調整。
- **スケジュールスケーリング**: 特定の時間や曜日に基づいてインスタンス数を増減。

#### 2.3 ライフサイクルフック

Auto Scaling は、EC2 インスタンスの起動時や終了時にカスタムアクションを実行するためのライフサイクルフックを提供する。  
これにより、インスタンスの起動時にアプリケーションの設定を行ったり、インスタンスの終了時にログを収集したりできる。

#### 2.4 ヘルスチェック

Auto Scaling は、EC2 インスタンスのヘルス状態を定期的にチェックし、異常なインスタンスを自動的に置き換える。  
これにより、アプリケーションの可用性と耐障害性を向上させる。

- **EC2 ヘルスチェック**: EC2 インスタンスのステータスを監視。
- **ELB ヘルスチェック**: Elastic Load Balancer に接続されたインスタンスのヘルスを監視。

#### 2.5 起動テンプレートと起動構成

Auto Scaling は、起動テンプレートまたは起動構成を使用して、EC2 インスタンスの起動設定を定義する。  
これにより、インスタンスの種類、AMI、セキュリティグループ、ストレージなどを定義できる。

- **起動テンプレート**: EC2 インスタンスの起動設定をテンプレートとして定義。
- **起動構成**: EC2 インスタンスの起動設定を構成として定義。

#### 2.6 可用性ゾーンの分散

Auto Scaling は、EC2 インスタンスを複数のアベイラビリティーゾーンに分散して起動できる。  
これにより、単一のアベイラビリティーゾーンで障害が発生した場合でも、アプリケーションの可用性を維持できる。

#### 2.7 統合性

Auto Scaling は、AWS の他のサービス（Elastic Load Balancing、Amazon CloudWatch、AWS CloudFormation など）と統合されており、スケーラブルで可用性の高いインフラを構築できる。  
AWS CodeDeploy と連携してアプリケーションのデプロイを自動化できる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、起動テンプレート（または起動構成）とスケーリングポリシーを定義して Auto Scaling グループを作成。
2. Auto Scaling グループは、定義された設定に基づいて EC2 インスタンスを起動。
3. Auto Scaling は、CloudWatch メトリクスを監視し、スケーリングポリシーに基づいてインスタンス数を自動的に調整。
4. Elastic Load Balancing は、トラフィックを正常なインスタンスに分散。
5. ライフサイクルフックが設定されている場合、インスタンスの起動時と終了時にカスタムアクションを実行。

Auto Scaling は、フルマネージドサービスとして提供され、高い可用性とスケーラビリティを内包している。  
需要に応じてリソースを自動的に調整し、アプリケーションの可用性を維持する。

### 4. セキュリティと認証・認可

セキュリティは EC2 Auto Scaling の重要な要素である:

- **IAM によるアクセス制御**: AWS IAM を利用して、Auto Scaling リソースへのアクセスを制御し、権限を管理。
- **セキュリティグループ**: EC2 インスタンスのインバウンド・アウトバウンドトラフィックを制御。
- **VPC サポート**: Amazon VPC 内で Auto Scaling を使用する場合、プライベート接続を確立。
- **暗号化**: 必要に応じて、ストレージの暗号化を有効化。
- **監査ログ**: AWS CloudTrail を利用して、API 呼び出しやリソース変更を記録。

これにより、インフラの安全性とコンプライアンスを確保できる。

### 5. 料金形態

Amazon EC2 Auto Scaling 自体の利用には料金はかかりない。  
ただし、Auto Scaling によって起動された EC2 インスタンス、および関連する AWS サービス（Elastic Load Balancing など）の利用料金が発生する。

- **EC2 インスタンス料金**: 起動された EC2 インスタンスの利用時間に応じた課金。
- **Elastic Load Balancing 料金**: ロードバランサーの利用時間、データ転送量に応じた課金。
- **CloudWatch 料金**: モニタリングデータの利用量に応じた課金。

### 6. よくあるアーキテクチャ・設計パターン

一般的なパターンは以下の通りである:

- **ウェブアプリケーションのスケーリング**: ウェブアプリケーションのトラフィックに応じて、EC2 インスタンスを自動的にスケーリング。
- **バッチ処理のスケーリング**: バッチ処理の負荷に応じて、EC2 インスタンスを自動的にスケーリング。
- **負荷テスト**: 負荷テスト中に EC2 インスタンスを自動的にスケーリングし、アプリケーションのパフォーマンスを確認。
- **災害復旧**: 障害発生時に、別のリージョンで EC2 インスタンスを自動的に起動し、アプリケーションを復旧。
- **アプリケーションの可用性向上**: 複数のアベイラビリティーゾーンにインスタンスを分散し、アプリケーションの可用性を向上。

### 7. 設定・デプロイ手順（ハンズオン例）

1. EC2 コンソールで起動テンプレート（または起動構成）を作成。
2. Auto Scaling コンソールで Auto Scaling グループを作成し、起動テンプレート（または起動構成）を指定。
3. スケーリングポリシーを定義（ターゲット追跡、ステップスケーリングなど）。
4. ヘルスチェックを設定（ELB ヘルスチェックなど）。
5. Auto Scaling グループを起動し、スケーリング動作を確認。

### 8. 試験で問われやすいポイント

#### 8.1 動的なスケーリング

- **自動スケーリング**: トラフィック変動に応じて EC2 インスタンス数を自動調整する仕組みを理解。
- **リソース効率**: 需要に応じてリソースを効率的に利用する方法を理解。

#### 8.2 スケーリングポリシー

- **ターゲット追跡スケーリング**: メトリクスに基づいた自動スケーリングを理解。
- **ステップスケーリング**: CloudWatch アラームに基づいて段階的にスケーリングする方法を理解。
- **スケジュールスケーリング**: 特定の時間や曜日でスケーリングする方法を理解。

#### 8.3 ライフサイクルフック

- **カスタムアクション**: インスタンス起動時・終了時にカスタムアクションを実行する方法を理解。
- **ユースケース**: アプリケーションの設定、ログ収集など、ライフサイクルフックのユースケースを理解。

#### 8.4 ヘルスチェック

- **ヘルスチェックの種類**: EC2 ヘルスチェック、ELB ヘルスチェックの違いを理解。
- **異常インスタンス**: 異常なインスタンスを自動的に置き換える仕組みを理解。

#### 8.5 起動テンプレートと起動構成

- **設定定義**: EC2 インスタンスの起動設定を定義する方法を理解。
- **違い**: 起動テンプレートと起動構成の違いを理解。

#### 8.6 可用性ゾーン分散

- **マルチ AZ**: 複数のアベイラビリティーゾーンにインスタンスを分散して可用性を向上させる方法を理解。

#### 8.7 料金体系

- **Auto Scaling 料金**: Auto Scaling 自体の料金は無料であることを理解。
- **関連サービス料金**: EC2 インスタンス、ELB、CloudWatch など、関連サービスの利用料金が発生することを理解。

#### 8.8 類似・関連サービスとの比較

- **AWS Elastic Beanstalk**: アプリケーションデプロイに特化。Auto Scaling はインフラのスケーリングに特化。
- **AWS Fargate**: コンテナのサーバーレス実行環境。Auto Scaling は EC2 インスタンスの管理。

#### 8.9 試験で頻出となる具体的な問われ方と答え

- Q: Amazon EC2 Auto Scaling の主な用途は？
  - A: 需要に応じて EC2 インスタンスを自動的に調整し、可用性、耐障害性、コスト効率を向上。
- Q: Auto Scaling がサポートするスケーリングポリシーの例は？
  - A: ターゲット追跡スケーリング、ステップスケーリング、スケジュールスケーリング。
- Q: ライフサイクルフックでできることは？
  - A: インスタンス起動時・終了時にカスタムアクションを実行。
- Q: Auto Scaling がサポートするヘルスチェックの種類は？
  - A: EC2 ヘルスチェック、ELB ヘルスチェック。
- Q: Auto Scaling で使用する EC2 インスタンスの起動設定は？
  - A: 起動テンプレートまたは起動構成。
- Q: Auto Scaling 自体の利用料金は？
  - A: 無料。
- Q: Auto Scaling と Elastic Beanstalk の違いは？
  - A: Elastic Beanstalk はアプリケーションデプロイ、Auto Scaling はインフラのスケーリング。

---

## AWS Auto Scaling

### 1. サービス概要

AWS Auto Scaling は、アプリケーションの需要に応じて、EC2 インスタンス、ECS タスク、DynamoDB テーブルなどの AWS リソースを自動的にスケーリングするためのサービスである。  
ユーザーは、手動でリソースを調整することなく、アプリケーションのパフォーマンスを維持し、コストを最適化できる。  
Auto Scaling は、アプリケーションの可用性、信頼性、コスト効率を向上させるために重要なサービスである。

主なユースケースとして、

- Web アプリケーションのスケーリング
- バッチ処理の負荷分散
- 機械学習ワークロードのスケーリング
- 予測に基づいたリソース調整
- 障害発生時の自動復旧

などが挙げられる。  
AWS Auto Scaling は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 動的なスケーリング

Auto Scaling は、アプリケーションの需要に応じて、リソースを自動的に増減させる。  
CPU 使用率、メモリ使用率、リクエスト数などのメトリクスに基づいて、スケーリングを実行できる。

#### 2.2 予測スケーリング

過去のトラフィックパターンを分析し、将来の需要を予測して、リソースを事前にスケーリングできる。  
これにより、トラフィックの急増に備え、アプリケーションのパフォーマンスを維持できる。

#### 2.3 スケジュールに基づくスケーリング

特定の日時や繰り返しのスケジュールに基づいて、リソースをスケーリングできる。  
例えば、週末や深夜にリソースを縮小し、平日の営業時間中にリソースを拡大するなどの設定が可能である。

#### 2.4 ヘルスチェック

Auto Scaling は、ヘルスチェックを通じて、インスタンスやアプリケーションの状態を監視し、障害が発生した場合には、自動的に新しいインスタンスを起動して、アプリケーションの可用性を維持する。

#### 2.5 ライフサイクルフック

インスタンスの起動や終了時に、カスタムアクションを実行するためのライフサイクルフックを設定できる。 これにより、インスタンスの準備やクリーンアップを自動化できる。

#### 2.6 スケーリングポリシー

Auto Scaling は、ターゲット追跡、ステップスケーリング、シンプルスケーリングなどの様々なスケーリングポリシーを提供する。 これらのポリシーを利用して、アプリケーションの要件に合わせて、スケーリング動作をカスタマイズできる。

#### 2.7 統合性と拡張性

AWS Auto Scaling は、EC2、ECS、DynamoDB、Aurora などの AWS の様々なサービスと統合されている。 また、API を利用して、Auto Scaling の動作を自動化することもできる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、Auto Scaling グループを作成し、スケーリングポリシー、ヘルスチェックなどを設定。
2. Auto Scaling は、設定されたメトリクスを監視し、スケーリングが必要かどうかを判断。
3. 必要に応じて、リソース（EC2 インスタンス、ECS タスクなど）を起動または終了。
4. ロードバランサーと連携し、リソースのトラフィックを分散。
5. ヘルスチェックで障害が発生した場合、新しいリソースを自動的に起動。

AWS Auto Scaling は、AWS のインフラ上に構築されており、高い可用性とスケーラビリティを提供する。  
リソースのスケーリングは AWS が行うため、ユーザーはインフラの管理を意識する必要はない。

### 4. セキュリティと認証・認可

AWS Auto Scaling は、AWS のセキュリティモデルに準拠しており、リソースのセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、Auto Scaling へのアクセスを制御する。
- **リソースの暗号化**: Auto Scaling で起動する EC2 インスタンスの EBS ボリュームは暗号化できる。
- **アクセス制御**: IAM ポリシーを通じて、ユーザーやグループごとに、Auto Scaling の操作権限を詳細に制御できる。
- **セキュリティグループ**: ネットワークアクセスをセキュリティグループで制御。

これらのセキュリティ対策により、Auto Scaling で管理されるリソースとそのデータを安全に保護する。

### 5. 料金形態

AWS Auto Scaling は、無料で利用できるサービスである。

ただし、Auto Scaling で起動する EC2 インスタンス、ECS タスク、その他の AWS リソースの利用料金は発生する。

### 6. よくあるアーキテクチャ・設計パターン

AWS Auto Scaling は、様々なアプリケーションのスケーリングに利用できる。  
一般的なパターンは以下の通りである:

- **Web アプリケーションのスケーリング**: Web アプリケーションのトラフィック増加に応じて、EC2 インスタンスを自動的にスケーリング。
- **マイクロサービスのスケーリング**: マイクロサービスごとに、ECS タスクを自動的にスケーリング。
- **バッチ処理の負荷分散**: バッチ処理の負荷に応じて、EC2 インスタンスを自動的にスケーリング。
- **機械学習ワークロードのスケーリング**: 機械学習モデルの学習や推論を行うリソースを自動的にスケーリング。
- **予測に基づいたリソース調整**: 過去のトラフィックパターンを分析し、将来の需要を予測して、リソースを事前にスケーリング。
- **障害発生時の自動復旧**: インスタンスの障害を検知し、自動的に新しいインスタンスを起動。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS マネジメントコンソールから AWS Auto Scaling を開き、Auto Scaling グループを作成。
2. 起動テンプレートまたは起動設定を選択し、EC2 インスタンスの設定を定義。
3. スケーリングポリシーを設定し、スケーリング動作を定義。
4. ヘルスチェックを設定し、インスタンスの状態を監視。
5. 必要に応じて、ライフサイクルフックを設定。
6. Auto Scaling グループを起動し、スケーリング動作を確認。

### 8. 試験で問われやすいポイント

#### 8.1 動的なスケーリング

- **機能**: アプリケーションの需要に応じて、リソースを自動的に増減。
- **メトリクス**: CPU 使用率、メモリ使用率、リクエスト数などに基づいてスケーリング。
- **試験対策**: スケーリングの仕組み、利用メトリクスが問われる。

#### 8.2 予測スケーリング

- **機能**: 過去のトラフィックパターンを分析し、将来の需要を予測してスケーリング。
- **目的**: トラフィックの急増に備え、パフォーマンスを維持。
- **試験対策**: 予測スケーリングの仕組み、メリットが問われる。

#### 8.3 スケジュールに基づくスケーリング

- **機能**: 特定の日時や繰り返しのスケジュールに基づいてリソースをスケーリング。
- **利用例**: 営業時間外のリソース縮小、営業時間中のリソース拡大。
- **試験対策**: スケジュール設定の方法、ユースケースが問われる。

#### 8.4 ヘルスチェック

- **機能**: インスタンスやアプリケーションの状態を監視。
- **目的**: 障害が発生した場合、新しいインスタンスを起動して可用性を維持。
- **試験対策**: ヘルスチェックの仕組み、重要性が問われる。

#### 8.5 ライフサイクルフック

- **機能**: インスタンスの起動や終了時にカスタムアクションを実行。
- **目的**: インスタンスの準備やクリーンアップを自動化。
- **試験対策**: ライフサイクルフックの設定、利用方法が問われる。

#### 8.6 スケーリングポリシー

- **種類**: ターゲット追跡、ステップスケーリング、シンプルスケーリングなど。
- **利用**: アプリケーションの要件に合わせてスケーリング動作をカスタマイズ。
- **試験対策**: 各ポリシーの違い、利用ケースが問われる。

#### 8.7 料金体系

- **料金**: AWS Auto Scaling 自体は無料。
- **関連料金**: Auto Scaling で起動する EC2 インスタンス、ECS タスクなどの利用料金が発生。
- **試験対策**: 料金体系、関連サービスの料金が問われる。

#### 8.8 類似・関連サービスとの比較

- **Amazon EC2 Auto Scaling**: EC2 インスタンスのスケーリングに特化したサービス。AWS Auto Scaling は複数のサービスに対応。
- **Amazon ECS Auto Scaling**: ECS タスクのスケーリングに特化したサービス。AWS Auto Scaling は複数のサービスに対応。

#### 8.9 試験で頻出となる具体的な問われ方と答え

- Q: AWS Auto Scaling は何を提供するサービスか？
  - A: アプリケーションの需要に応じて、AWS リソースを自動的にスケーリングするためのサービスである。
- Q: AWS Auto Scaling のスケーリングは、どのようなメトリクスに基づいて実行できるか？
  - A: CPU 使用率、メモリ使用率、リクエスト数などのメトリクスに基づいて実行できる。
- Q: AWS Auto Scaling で予測スケーリングは何をするか？
  - A: 過去のトラフィックパターンを分析し、将来の需要を予測して、リソースを事前にスケーリングする。
- Q: AWS Auto Scaling のヘルスチェックの目的は何か？
  - A: インスタンスやアプリケーションの状態を監視し、障害が発生した場合には、自動的に新しいインスタンスを起動して、アプリケーションの可用性を維持することである。
- Q: AWS Auto Scaling の料金はどのように計算されるか？
  - A: AWS Auto Scaling 自体は無料であるが、Auto Scaling で起動するリソースの利用料金は発生する。

---

## AWS Batch

### 1. サービス概要

AWS Batch は、バッチコンピューティングジョブを簡単に実行できるフルマネージドサービスである。  
開発者や科学者は、大規模なバッチ処理ワークロードを AWS で効率的に実行し、インフラストラクチャの管理に煩わされることなく、ジョブの実行に集中できる。  
AWS Batch は、コンピューティングリソースを自動的にプロビジョニングし、ジョブの実行をスケジュールし、ジョブの進捗状況を監視する。

主なユースケースとして、ゲノム解析、気象シミュレーション、金融リスク分析、画像処理、動画変換、データ変換、機械学習の学習などが挙げられる。  
AWS Batch は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 フルマネージドサービス

AWS Batch は、バッチコンピューティングジョブの実行をフルマネージドで提供する。  
ユーザーは、コンピューティング環境の管理やジョブのスケジューリングを AWS に任せ、ジョブの実行に集中できる。

#### 2.2 ジョブの定義

実行するバッチジョブを定義できる。  
ジョブの定義には、コンテナイメージ、コマンド、リソース要件、環境変数などの情報を指定する。

#### 2.3 コンピューティング環境

ジョブを実行するためのコンピューティング環境を定義できる。  
コンピューティング環境は、EC2 インスタンスまたは Fargate で構成できる。

#### 2.4 ジョブキュー

実行するジョブをキューに追加し、AWS Batch が適切なコンピューティング環境でジョブをスケジュールし、実行する。  
優先度を設定することで、ジョブの実行順序を制御できる。

#### 2.5 スケーラビリティ

ジョブの負荷に応じて、コンピューティングリソースを自動的にスケーリングできる。  
これにより、大量のバッチ処理ジョブを効率的に実行できる。

#### 2.6 依存関係の管理

ジョブ間に依存関係を設定できる。  
これにより、あるジョブが完了した後に、次のジョブを自動的に実行できる。

#### 2.7 統合性と拡張性

AWS Batch は、Amazon S3、Amazon DynamoDB、AWS Lambda などの AWS の他のサービスと統合できる。  
また、API を利用して、ジョブの管理や自動化を行うこともできる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、ジョブ定義とコンピューティング環境を AWS Batch に登録。
2. ジョブをジョブキューに追加し、実行をリクエスト。
3. AWS Batch は、ジョブの実行に必要なコンピューティングリソースをプロビジョニング。
4. ジョブは、定義された環境で実行。
5. ジョブの進捗状況を監視し、完了時に通知。

AWS Batch は、AWS のインフラ上に構築されており、高い可用性とスケーラビリティを提供する。  
コンピューティング環境の管理やジョブのスケジューリングは AWS が行うため、ユーザーはインフラの管理を行う必要はない。

### 4. セキュリティと認証・認可

AWS Batch は、AWS のセキュリティモデルに準拠しており、ジョブのセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、AWS Batch へのアクセスを制御する。
- **VPC 内での実行**: ジョブは Virtual Private Cloud (VPC) 内で実行され、ネットワーク隔離を実現。
- **ジョブロール**: ジョブに IAM ロールを割り当て、AWS リソースへのアクセスを制御。
- **データ暗号化**: ジョブデータは転送中および保存時に暗号化される。
- **セキュリティグループ**: ネットワークアクセスをセキュリティグループで制御。

これらのセキュリティ対策により、ジョブとそのデータを安全に保護する。

### 5. 料金形態

AWS Batch の料金は主に以下に基づきる:

- **EC2 インスタンス**: コンピューティング環境に EC2 インスタンスを使用した場合、EC2 インスタンスの利用料金。
- **Fargate**: コンピューティング環境に Fargate を使用した場合、Fargate の使用量に応じた料金。
- **データ転送**: データ転送量に応じて課金。

### 6. よくあるアーキテクチャ・設計パターン

AWS Batch は、様々なバッチ処理ワークロードに利用できる。一般的なパターンは以下の通りである:

- **ゲノム解析**: 大量のゲノムデータを処理するジョブを AWS Batch で実行。
- **気象シミュレーション**: 大規模な気象シミュレーションを AWS Batch で実行。
- **金融リスク分析**: 金融リスク分析に必要な計算処理を AWS Batch で実行。
- **画像処理**: 画像の変換、加工処理を AWS Batch で実行。
- **動画変換**: 動画ファイルの変換、エンコード処理を AWS Batch で実行。
- **機械学習の学習**: 機械学習モデルの学習を AWS Batch で実行。
- **データ変換**: データを変換するジョブを AWS Batch で実行。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS マネジメントコンソールから AWS Batch を開き、ジョブ定義を作成。
2. コンピューティング環境を作成し、EC2 インスタンスまたは Fargate を設定。
3. ジョブキューを作成し、ジョブ定義を関連付け。
4. ジョブをジョブキューに追加し、実行。
5. ジョブの進捗状況を監視し、結果を確認。

### 8. 試験で問われやすいポイント

#### 8.1 フルマネージドサービス

- **機能**: バッチコンピューティングジョブの実行をフルマネージドで提供。
- **対象**: コンピューティング環境の管理やジョブのスケジューリングを AWS が担当。
- **試験対策**: フルマネージドのメリット、管理範囲が問われる。

#### 8.2 ジョブの定義

- **内容**: コンテナイメージ、コマンド、リソース要件、環境変数など。
- **利用**: 実行するバッチジョブを定義。
- **試験対策**: ジョブ定義の内容、設定方法が問われる。

#### 8.3 コンピューティング環境

- **種類**: EC2 インスタンス、Fargate。
- **利用**: ジョブを実行するためのコンピューティングリソースを定義。
- **試験対策**: EC2 と Fargate の違い、利用ケースが問われる。

#### 8.4 ジョブキュー

- **機能**: 実行するジョブをキューに追加。
- **利用**: AWS Batch が適切なコンピューティング環境でジョブをスケジュールし、実行。
- **試験対策**: ジョブキューの役割、優先度設定が問われる。

#### 8.5 スケーラビリティ

- **機能**: ジョブの負荷に応じて、コンピューティングリソースを自動的にスケーリング。
- **目的**: 大量のバッチ処理ジョブを効率的に実行。
- **試験対策**: スケーリングの仕組み、メリットが問われる。

#### 8.6 依存関係の管理

- **機能**: ジョブ間に依存関係を設定。
- **利用**: あるジョブが完了した後に、次のジョブを自動的に実行。
- **試験対策**: 依存関係の設定、利用シーンが問われる。

#### 8.7 料金体系

- **課金対象**: EC2 インスタンス、Fargate の使用量、データ転送量。
- **最適化**: コンピューティング環境の選択、リソース使用量の最適化がコスト削減に有効。
- **試験対策**: 料金体系、課金対象が問われる。

#### 8.8 類似・関連サービスとの比較

- **AWS Step Functions**: ワークフローを管理するサービス。Batch はバッチ処理に特化。
- **AWS Lambda**: イベント駆動型のサーバーレスコンピューティングサービス。Batch はバッチ処理に特化。

#### 8.9 試験で頻出となる具体的な問われ方と答え

- Q: AWS Batch は何を提供するサービスか？
  - A: バッチコンピューティングジョブを簡単に実行できるフルマネージドサービスである。
- Q: AWS Batch で実行するジョブはどのように定義するか？
  - A: ジョブ定義に、コンテナイメージ、コマンド、リソース要件、環境変数などの情報を指定する。
- Q: AWS Batch のコンピューティング環境には、どのような選択肢があるか？
  - A: EC2 インスタンスまたは Fargate を選択できる。
- Q: AWS Batch でジョブの実行をスケジュールするには、どうすればよいか？
  - A: ジョブをジョブキューに追加することで、AWS Batch が適切なコンピューティング環境でジョブをスケジュールし、実行する。
- Q: AWS Batch の料金はどのように計算されるか？
  - A: EC2 インスタンス、Fargate の使用量、データ転送量に基づいて計算される。

---

## AWS Compute Optimizer

### 1. サービス概要

AWS Compute Optimizer は、AWS リソースの使用状況を分析し、最適なリソース構成を推奨するサービスである。  
ユーザーは、EC2 インスタンス、Auto Scaling グループ、EBS ボリューム、AWS Lambda 関数などのリソースの利用状況を分析し、パフォーマンスを維持しながらコストを削減するための推奨事項を得ることができる。  
Compute Optimizer は、機械学習を利用して、リソースの過剰プロビジョニングやリソース不足を特定し、より効率的なリソース利用を支援する。

主なユースケースとして、

- EC2 インスタンスのサイズ最適化
- Auto Scaling グループの構成最適化
- EBS ボリュームのタイプ最適化
- Lambda 関数のメモリ最適化
- リソースのコスト削減
- パフォーマンス向上

などが挙げられる。  
AWS Compute Optimizer は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 リソース使用状況の分析

Compute Optimizer は、EC2 インスタンス、Auto Scaling グループ、EBS ボリューム、Lambda 関数などの AWS リソースの使用状況データを収集し、分析する。  
CPU 使用率、メモリ使用率、ディスク I/O などのメトリクスに基づいて、リソースのパフォーマンスを評価する。

#### 2.2 推奨事項の生成

分析結果に基づいて、最適なリソース構成を推奨する。  
例えば、EC2 インスタンスのサイズ変更、Auto Scaling グループの構成調整、EBS ボリュームのタイプ変更などを提案する。

#### 2.3 コストとパフォーマンスの最適化

推奨事項は、コスト削減とパフォーマンス向上を両立するように設計されている。  
Compute Optimizer は、リソースの過剰プロビジョニングを避け、リソース不足を解消することで、コストとパフォーマンスを最適化する。

#### 2.4 機械学習ベースの分析

Compute Optimizer は、機械学習を利用して、リソースの使用状況を分析する。  
これにより、より正確で適切な推奨事項を提供できる。

#### 2.5 エクスポート機能

推奨事項や分析結果を CSV 形式でエクスポートできる。  
エクスポートしたデータは、他のツールで分析したり、チームで共有したりできる。

#### 2.6 拡張性と統合性

AWS Compute Optimizer は、AWS Organizations と統合し、組織全体のリソース使用状況を分析できる。  
また、API を利用して、推奨事項の取得を自動化することもできる。

#### 2.7 ダッシュボード

Compute Optimizer は、推奨事項を一覧表示するダッシュボードを提供する。  
ダッシュボードでは、推奨事項の状態や重要度などを確認できる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、AWS マネジメントコンソールまたは API を通じて、AWS Compute Optimizer にアクセス。
2. Compute Optimizer は、AWS の各サービスからリソースの使用状況データを収集。
3. 収集したデータに基づいて、機械学習モデルを利用して分析。
4. 分析結果に基づいて、最適なリソース構成を推奨。
5. ユーザーは、推奨事項を確認し、リソース構成を調整。

AWS Compute Optimizer は、AWS のインフラ上に構築されており、高い可用性とスケーラビリティを提供する。  
リソース使用状況データの収集や分析は AWS が行うため、ユーザーはインフラの管理を行う必要はない。

### 4. セキュリティと認証・認可

AWS Compute Optimizer は、AWS のセキュリティモデルに準拠しており、リソース使用状況データのセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、Compute Optimizer へのアクセスを制御する。
- **データ暗号化**: 使用状況データは転送中および保存時に暗号化される。
- **アクセス制御**: IAM ポリシーを通じて、ユーザーやグループごとに、Compute Optimizer の操作権限を詳細に制御できる。
- **監査ログ**: CloudTrail を通じて、Compute Optimizer の利用状況を監査できる。

これらのセキュリティ対策により、リソース使用状況データへの不正アクセスを防止し、機密情報を保護できる。

### 5. 料金形態

AWS Compute Optimizer は、無料で利用できるサービスである。

ただし、Compute Optimizer で推奨されたリソース構成に変更を行う場合、変更後のリソースの利用料金が発生する。

### 6. よくあるアーキテクチャ・設計パターン

AWS Compute Optimizer は、様々な AWS 利用環境で利用できる。一般的なパターンは以下の通りである:

- **EC2 インスタンスのサイズ最適化**: EC2 インスタンスの CPU、メモリ使用率を分析し、適切なインスタンスタイプを推奨。
- **Auto Scaling グループの構成最適化**: Auto Scaling グループの最小、最大インスタンス数、スケールアウト/インポリシーを最適化。
- **EBS ボリュームのタイプ最適化**: EBS ボリュームの I/O 性能を分析し、最適なボリュームタイプ（gp2, gp3, io1 など）を推奨。
- **Lambda 関数のメモリ最適化**: Lambda 関数の実行時間とメモリ使用量を分析し、最適なメモリサイズを推奨。
- **リソースのコスト削減**: リソースの過剰プロビジョニングを避け、適切なリソース構成を選択することで、コストを削減。
- **パフォーマンス向上**: リソース不足を解消し、アプリケーションのパフォーマンスを向上。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS マネジメントコンソールから AWS Compute Optimizer を開き、リソース分析を開始。
2. Compute Optimizer が生成した推奨事項を確認。
3. EC2 インスタンス、Auto Scaling グループ、EBS ボリューム、Lambda 関数などのリソースを推奨事項に基づいて調整。
4. 調整後のリソースのパフォーマンスとコストを監視。

### 8. 試験で問われやすいポイント

#### 8.1 リソース使用状況の分析

- **分析対象**: EC2 インスタンス、Auto Scaling グループ、EBS ボリューム、Lambda 関数。
- **メトリクス**: CPU 使用率、メモリ使用率、ディスク I/O など。
- **試験対策**: 分析対象、利用メトリクスが問われる。

#### 8.2 推奨事項の生成

- **内容**: EC2 インスタンスのサイズ変更、Auto Scaling グループの構成調整、EBS ボリュームのタイプ変更など。
- **目的**: コスト削減とパフォーマンス向上。
- **試験対策**: 推奨事項の内容、利用ケースが問われる。

#### 8.3 コストとパフォーマンスの最適化

- **目的**: リソースの過剰プロビジョニングを避け、リソース不足を解消。
- **効果**: コスト削減とパフォーマンス向上を両立。
- **試験対策**: 最適化の目的、効果が問われる。

#### 8.4 機械学習ベースの分析

- **利用技術**: 機械学習。
- **目的**: より正確で適切な推奨事項を提供。
- **試験対策**: 機械学習の利用目的、メリットが問われる。

#### 8.5 エクスポート機能

- **形式**: CSV 形式。
- **利用**: 他のツールで分析、チームで共有。
- **試験対策**: エクスポート機能、利用方法が問われる。

#### 8.6 料金体系

- **料金**: AWS Compute Optimizer 自体は無料。
- **関連料金**: 推奨事項に基づいてリソースを変更した場合、リソース利用料金が発生。
- **試験対策**: 料金体系、関連サービスの料金が問われる。

#### 8.7 類似・関連サービスとの比較

- **AWS Trusted Advisor**: コスト削減、セキュリティ、パフォーマンスの改善に関する推奨事項を提供。Compute Optimizer はリソースの最適化に特化。

#### 8.8 試験で頻出となる具体的な問われ方と答え

- Q: AWS Compute Optimizer は何を提供するサービスか？
  - A: AWS リソースの使用状況を分析し、最適なリソース構成を推奨するサービスである。
- Q: AWS Compute Optimizer は、どのようなリソースの推奨事項を生成するか？
  - A: EC2 インスタンス、Auto Scaling グループ、EBS ボリューム、Lambda 関数などのリソースの推奨事項を生成する。
- Q: AWS Compute Optimizer の推奨事項は、どのような目的で設計されているか？
  - A: コスト削減とパフォーマンス向上を両立するように設計されている。
- Q: AWS Compute Optimizer は何を利用して、リソースの使用状況を分析するか？
  - A: 機械学習を利用して分析する。
- Q: AWS Compute Optimizer の料金は？
  - A: 無料で利用できる。

---

## AWS Elastic Beanstalk

### 1. サービス概要

AWS Elastic Beanstalk は、Web アプリケーションや Web サービスを AWS クラウドに簡単にデプロイ、管理できるプラットフォームサービスである。  
ユーザーは、アプリケーションコードをアップロードするだけで、必要なインフラストラクチャ（EC2 インスタンス、ロードバランサー、データベースなど）が自動的にプロビジョニングされ、アプリケーションがデプロイされる。  
Elastic Beanstalk は、アプリケーションのデプロイメントと管理を簡素化し、開発者がアプリケーション開発に集中できるようにする。

主なユースケースとして、

- Web アプリケーションのデプロイ
- RESTful API のデプロイ
- モバイルアプリケーションのバックエンド
- プロトタイプ開発
- テスト環境の構築

などが挙げられる。  
AWS Elastic Beanstalk は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 プラットフォームとしてのサービス (PaaS)

Elastic Beanstalk は、プラットフォームとしてのサービス（PaaS）を提供する。  
ユーザーは、アプリケーションコードをアップロードするだけで、インフラストラクチャの管理を AWS に任せることができる。

#### 2.2 多様なプラットフォームのサポート

Java, .NET, PHP, Node.js, Python, Ruby, Go などの様々なプログラミング言語と、Tomcat, Apache, IIS などの Web サーバーをサポートしている。  
これにより、多様なアプリケーションをデプロイできる。

#### 2.3 環境のカスタマイズ

環境の構成（EC2 インスタンスのタイプ、Auto Scaling の設定、ロードバランサーの設定など）をカスタマイズできる。  
これにより、アプリケーションの要件に合わせたインフラストラクチャを構築できる。

#### 2.4 環境のデプロイと管理

アプリケーションのデプロイ、バージョン管理、環境の構成変更などを簡単に行える。  
AWS マネジメントコンソール、CLI、API を通じて、環境を管理できる。

#### 2.5 ロードバランシングと Auto Scaling

Elastic Beanstalk は、ロードバランサーと Auto Scaling を統合しており、アプリケーションのトラフィックを分散し、可用性を高め、需要に応じてリソースを自動的にスケーリングできる。

#### 2.6 ヘルスチェック

アプリケーションの状態を監視し、障害が発生した場合には、自動的に新しいインスタンスを起動して、アプリケーションの可用性を維持する。

#### 2.7 統合性と拡張性

AWS Elastic Beanstalk は、RDS、S3、CloudWatch、IAM などの AWS の他のサービスと密接に統合されている。  
また、CI/CD パイプラインを構築するための AWS CodePipeline と連携できる。

### 3. アーキテクチャおよび技術要素

1. 開発者は、アプリケーションコードをパッケージ化し、Elastic Beanstalk にアップロード。
2. Elastic Beanstalk は、指定されたプラットフォームと設定に基づき、EC2 インスタンス、ロードバランサーなどを自動的にプロビジョニング。
3. アプリケーションは、プロビジョニングされたインフラストラクチャ上で実行。
4. ユーザーは、アプリケーションにアクセス。
5. Elastic Beanstalk は、アプリケーションの状態を監視し、必要に応じてリソースを自動的にスケーリング。

AWS Elastic Beanstalk は、AWS のインフラ上に構築されており、高い可用性とスケーラビリティを提供する。  
インフラストラクチャのプロビジョニングや管理は AWS が行うため、ユーザーはアプリケーション開発に集中できる。

### 4. セキュリティと認証・認可

AWS Elastic Beanstalk は、AWS のセキュリティモデルに準拠しており、アプリケーションのセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、Elastic Beanstalk へのアクセスを制御する。
- **VPC 内での実行**: アプリケーションは Virtual Private Cloud (VPC) 内で実行され、ネットワーク隔離を実現。
- **セキュリティグループ**: ネットワークアクセスをセキュリティグループで制御。
- **データ暗号化**: アプリケーションデータは転送中および保存時に暗号化される。
- **SSL/TLS**: HTTPS でアプリケーションへのアクセスを保護。

これらのセキュリティ対策により、アプリケーションとそのデータを安全に保護する。

### 5. 料金形態

AWS Elastic Beanstalk は、無料で利用できるサービスである。

ただし、Elastic Beanstalk でプロビジョニングされる EC2 インスタンス、ロードバランサー、データベースなどの AWS リソースの利用料金は発生する。

### 6. よくあるアーキテクチャ・設計パターン

AWS Elastic Beanstalk は、様々な Web アプリケーションや Web サービスのデプロイメントに利用できる。  
一般的なパターンは以下の通りである:

- **Web アプリケーションのデプロイ**: Web アプリケーションを Elastic Beanstalk にデプロイし、ユーザーに公開。
- **RESTful API のデプロイ**: RESTful API を Elastic Beanstalk にデプロイし、モバイルアプリや Web アプリケーションから利用。
- **モバイルアプリケーションのバックエンド**: モバイルアプリケーションのバックエンドを Elastic Beanstalk にデプロイし、データベースと連携。
- **プロトタイプ開発**: アプリケーションのプロトタイプを Elastic Beanstalk に迅速にデプロイし、テスト。
- **テスト環境の構築**: アプリケーションのテストに必要な環境を Elastic Beanstalk に構築。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS マネジメントコンソールから AWS Elastic Beanstalk を開き、新しいアプリケーションを作成。
2. 環境を作成し、プラットフォーム（Java, .NET, PHP など）を選択。
3. アプリケーションコードをアップロード。
4. 必要に応じて、環境設定（EC2 インスタンスタイプ、Auto Scaling など）をカスタマイズ。
5. 環境をデプロイし、アプリケーションにアクセス。
6. アプリケーションを更新し、バージョニングを行う。

### 8. 試験で問われやすいポイント

#### 8.1 プラットフォームとしてのサービス (PaaS)

- **機能**: アプリケーションコードをアップロードするだけで、インフラ管理を AWS に任せられる。
- **対象**: インフラストラクチャのプロビジョニング、管理。
- **試験対策**: PaaS のメリット、管理範囲が問われる。

#### 8.2 多様なプラットフォームのサポート

- **サポート対象**: Java, .NET, PHP, Node.js, Python, Ruby, Go など。
- **利用**: 多様なアプリケーションをデプロイ可能。
- **試験対策**: サポートされるプラットフォーム、利用ケースが問われる。

#### 8.3 環境のカスタマイズ

- **対象**: EC2 インスタンスタイプ、Auto Scaling 設定、ロードバランサー設定など。
- **目的**: アプリケーションの要件に合わせたインフラストラクチャを構築。
- **試験対策**: 環境設定のカスタマイズ範囲、設定項目が問われる。

#### 8.4 環境のデプロイと管理

- **機能**: アプリケーションのデプロイ、バージョン管理、構成変更。
- **管理方法**: AWS マネジメントコンソール、CLI、API。
- **試験対策**: デプロイと管理の方法、利用ツールが問われる。

#### 8.5 ロードバランシングと Auto Scaling

- **統合**: ロードバランサーと Auto Scaling を統合。
- **機能**: トラフィック分散、可用性向上、自動スケーリング。
- **試験対策**: ロードバランシングと Auto Scaling の連携、メリットが問われる。

#### 8.6 料金体系

- **料金**: AWS Elastic Beanstalk 自体は無料。
- **関連料金**: プロビジョニングされる EC2 インスタンス、ロードバランサー、データベースなどの利用料金が発生。
- **試験対策**: 料金体系、関連サービスの料金が問われる。

#### 8.7 類似・関連サービスとの比較

- **AWS CodeDeploy**: アプリケーションのデプロイを自動化するサービス。Elastic Beanstalk はインフラのプロビジョニングも行う。
- **Amazon EC2**: 仮想サーバーサービス。Elastic Beanstalk はアプリケーションデプロイに特化。

#### 8.8 試験で頻出となる具体的な問われ方と答え

- Q: AWS Elastic Beanstalk は何を提供するサービスか？
  - A: Web アプリケーションや Web サービスを AWS クラウドに簡単にデプロイ、管理できるプラットフォームサービスである。
- Q: AWS Elastic Beanstalk でサポートされているプラットフォームは何か？
  - A: Java, .NET, PHP, Node.js, Python, Ruby, Go などの様々なプログラミング言語と、Tomcat, Apache, IIS などの Web サーバーをサポートしている。
- Q: AWS Elastic Beanstalk の環境はどのようにカスタマイズできるか？
  - A: EC2 インスタンスのタイプ、Auto Scaling の設定、ロードバランサーの設定などをカスタマイズできる。
- Q: AWS Elastic Beanstalk でロードバランシングと Auto Scaling はどのように利用されるか？
  - A: アプリケーションのトラフィックを分散し、可用性を高め、需要に応じてリソースを自動的にスケーリングするために利用される。
- Q: AWS Elastic Beanstalk の料金はどのように計算されるか？
  - A: AWS Elastic Beanstalk 自体は無料であるが、プロビジョニングされる EC2 インスタンス、ロードバランサー、データベースなどの AWS リソースの利用料金が発生する。

---

## AWS Lambda

### 1. サービス概要

AWS Lambda は、サーバーレスコンピューティングサービスであり、ユーザーはサーバーのプロビジョニングや管理をすることなく、コードを実行できる。  
ユーザーは、イベントをトリガーとして、コード（関数）をアップロードするだけで、自動的にコードが実行される。 Lambda は、イベント駆動型アプリケーションの開発、バッチ処理、リアルタイムデータ処理など、様々なユースケースに対応できる。

主なユースケースとして、

- Web アプリケーションのバックエンド
- API の処理
- モバイルアプリケーションのバックエンド
- データ変換処理
- ストリーミングデータ処理
- チャットボット
- IoT デバイスからのデータ処理

などが挙げられる。  
AWS Lambda は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 サーバーレスコンピューティング

Lambda は、サーバーのプロビジョニングや管理を必要としないサーバーレスコンピューティングを提供する。  
ユーザーは、コードをアップロードするだけで、自動的に実行される。

#### 2.2 イベント駆動型アーキテクチャ

Lambda 関数は、様々な AWS サービスからのイベントをトリガーとして実行できる。  
例えば、S3 バケットへのオブジェクトのアップロード、DynamoDB テーブルへのデータの書き込み、API Gateway へのリクエストなどをトリガーとして、Lambda 関数を実行できる。

#### 2.3 自動スケーリング

Lambda は、受信したイベント数に応じて、自動的にリソースをスケーリングする。  
これにより、トラフィックの変動に対応し、安定したパフォーマンスを提供できる。

#### 2.4 実行時間とメモリの調整

Lambda 関数の実行時間とメモリ量を調整できる。  
これにより、リソースの利用率を最適化し、コストを削減できる。

#### 2.5 多様なランタイムのサポート

Python, Node.js, Java, Go, Ruby, .NET などの様々なプログラミング言語をサポートしている。  
また、カスタムランタイムを利用して、任意の言語や環境で Lambda 関数を実行できる。

#### 2.6 バージョン管理

Lambda 関数のバージョンを管理できる。  
これにより、関数を安全に更新し、必要に応じて以前のバージョンに戻すことができる。

#### 2.7 統合性と拡張性

AWS Lambda は、S3, DynamoDB, API Gateway, SNS, SQS, Kinesis などの AWS の他のサービスと密接に統合されており、様々なアプリケーションを構築できる。  
また、API を利用して、Lambda 関数の管理を自動化することもできる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、Lambda 関数を作成し、トリガーとなるイベントを設定。
2. イベントが発生すると、Lambda 関数が自動的に実行。
3. Lambda 関数は、必要な処理を実行し、結果を返す。
4. 必要に応じて、他の AWS サービスと連携。
5. Lambda は、関数の実行状況を監視し、自動スケーリングを適用。

AWS Lambda は、AWS のインフラ上に構築されており、高い可用性とスケーラビリティを提供する。  
サーバーのプロビジョニングや管理は AWS が行うため、ユーザーはコードの実行に集中できる。

### 4. セキュリティと認証・認可

AWS Lambda は、サーバーレスコンピューティング環境のセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、Lambda 関数へのアクセスを制御する。
- **VPC 内での実行**: Lambda 関数は Virtual Private Cloud (VPC) 内で実行でき、ネットワーク隔離を実現。
- **実行ロール**: Lambda 関数に IAM ロールを割り当て、AWS リソースへのアクセスを制御。
- **データ暗号化**: 環境変数や保存データは暗号化される。
- **アクセス制御**: IAM ポリシーを通じて、ユーザーやグループごとに、Lambda 関数の操作権限を詳細に制御できる。

これらのセキュリティ対策により、Lambda 関数とそのデータを安全に保護する。

### 5. 料金形態

AWS Lambda の料金は主に以下に基づきる:

- **リクエスト数**: Lambda 関数が呼び出された回数に応じて課金。
- **実行時間**: Lambda 関数が実行された時間（ミリ秒単位）に応じて課金。
- **メモリ使用量**: Lambda 関数に割り当てられたメモリ量に応じて課金。
- **データ転送**: データ転送量に応じて課金。

### 6. よくあるアーキテクチャ・設計パターン

AWS Lambda は、様々なアプリケーション開発に利用できる。  
一般的なパターンは以下の通りである:

- **Web アプリケーションのバックエンド**: API Gateway と連携し、Web アプリケーションのバックエンドロジックを Lambda 関数で処理。
- **API の処理**: API Gateway からのリクエストを Lambda 関数で処理し、レスポンスを返す。
- **モバイルアプリケーションのバックエンド**: モバイルアプリケーションのバックエンドロジックを Lambda 関数で処理。
- **データ変換処理**: S3 にアップロードされたデータを Lambda 関数で変換し、DynamoDB などに保存。
- **ストリーミングデータ処理**: Kinesis や Kafka などのストリーミングデータソースからデータを受け取り、Lambda 関数で処理。
- **チャットボット**: チャットボットのロジックを Lambda 関数で実装し、ユーザーからの問い合わせに対応。
- **IoT デバイスからのデータ処理**: IoT デバイスから送信されたデータを Lambda 関数で処理し、データベースや他のサービスに連携。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS マネジメントコンソールから AWS Lambda を開き、新しい関数を作成。
2. ランタイム（Python, Node.js など）を選択し、関数コードを記述。
3. トリガーとなるイベント（S3, API Gateway など）を設定。
4. 必要に応じて、環境変数や VPC 設定を設定。
5. Lambda 関数を実行し、動作を確認。

### 8. 試験で問われやすいポイント

#### 8.1 サーバーレスコンピューティング

- **特徴**: サーバーのプロビジョニングや管理が不要。
- **利用**: コードをアップロードするだけで実行可能。
- **試験対策**: サーバーレスのメリット、管理範囲が問われる。

#### 8.2 イベント駆動型アーキテクチャ

- **トリガー**: S3, DynamoDB, API Gateway, SNS, SQS, Kinesis など。
- **機能**: イベントをトリガーとして Lambda 関数を実行。
- **試験対策**: イベントソース、トリガーの仕組みが問われる。

#### 8.3 自動スケーリング

- **機能**: 受信したイベント数に応じて、自動的にリソースをスケーリング。
- **目的**: トラフィックの変動に対応し、安定したパフォーマンスを提供。
- **試験対策**: 自動スケーリングの仕組み、メリットが問われる。

#### 8.4 実行時間とメモリの調整

- **設定項目**: 実行時間とメモリ量を調整可能。
- **目的**: リソースの利用率を最適化し、コストを削減。
- **試験対策**: 調整可能な設定項目、コスト最適化が問われる。

#### 8.5 多様なランタイムのサポート

- **サポート言語**: Python, Node.js, Java, Go, Ruby, .NET など。
- **拡張**: カスタムランタイムを利用可能。
- **試験対策**: サポートされるランタイム、カスタムランタイムの利用が問われる。

#### 8.6 料金体系

- **課金対象**: リクエスト数、実行時間、メモリ使用量、データ転送量。
- **最適化**: 実行時間とメモリ使用量を最適化し、コストを削減。
- **試験対策**: 料金体系、課金対象が問われる。

#### 8.7 類似・関連サービスとの比較

- **AWS Fargate**: コンテナを実行するためのサーバーレスコンピューティングサービス。Lambda はイベント駆動型のコード実行に特化。
- **AWS Batch**: バッチ処理ジョブを実行するサービス。Lambda はリアルタイム処理やイベント駆動型処理に特化。

#### 8.8 試験で頻出となる具体的な問われ方と答え

- Q: AWS Lambda は何を提供するサービスか？
  - A: サーバーのプロビジョニングや管理をすることなく、コードを実行できるサーバーレスコンピューティングサービスである。
- Q: AWS Lambda 関数は、どのようなイベントをトリガーとして実行できるか？
  - A: S3 バケットへのオブジェクトのアップロード、DynamoDB テーブルへのデータの書き込み、API Gateway へのリクエストなどをトリガーとして実行できる。
- Q: AWS Lambda はどのようにスケーリングするか？
  - A: 受信したイベント数に応じて、自動的にリソースをスケーリングする。
- Q: AWS Lambda で調整できるリソースは何か？
  - A: 実行時間とメモリ量を調整できる。
- Q: AWS Lambda の料金はどのように計算されるか？
  - A: リクエスト数、実行時間、メモリ使用量、データ転送量に基づいて計算される。

---

## AWS Outposts

### 1. サービス概要

AWS Outposts は、AWS のインフラストラクチャ、サービス、API、およびツールを、オンプレミス環境に拡張できるサービスである。  
ユーザーは、自社のデータセンター、コワーキングスペース、またはオンプレミス環境に AWS のハードウェアを設置し、AWS クラウドと同じ環境でアプリケーションを実行できる。  
これにより、オンプレミス環境で必要な低レイテンシー、ローカルデータ処理、データ所在地の要件を満たしつつ、AWS の利点を活用できる。

主なユースケースとして、

- ローカルデータ処理
- 低レイテンシーアプリケーション
- データ所在地の要件を満たすアプリケーション
- ハイブリッドクラウド環境
- データ分析処理

などが挙げられる。  
AWS Outposts は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 オンプレミスへの AWS 拡張

Outposts は、AWS のインフラストラクチャ、サービス、API、およびツールを、オンプレミス環境に拡張する。  
これにより、AWS クラウドと同じ環境をオンプレミス環境でも利用できる。

#### 2.2 ローカルデータ処理

Outposts でアプリケーションを実行することで、データをオンプレミス環境でローカルに処理でき、クラウドへのデータ転送に伴うレイテンシーや帯域幅の制約を回避できる。

#### 2.3 低レイテンシーアプリケーションの実行

Outposts は、エンドユーザーに近い場所でアプリケーションを実行できるため、低レイテンシーが重要なアプリケーションのパフォーマンスを向上させることができる。  
これにより、リアルタイムアプリケーションやインタラクティブなアプリケーションの応答時間を短縮できる。

#### 2.4 ハイブリッドクラウド環境

オンプレミス環境と AWS クラウド環境をシームレスに連携させることができる。  
これにより、アプリケーションを柔軟に配置し、最適なリソース利用が可能である。

#### 2.5 AWS サービスとの統合

Outposts は、EC2、EBS、VPC、RDS、ECS、EKS、Lambda など、様々な AWS サービスと統合できる。  
これにより、AWS クラウドと同じように、アプリケーションを開発、デプロイできる。

#### 2.6 フルマネージドサービス

Outposts のハードウェアの管理やメンテナンスは AWS が行うため、ユーザーはインフラストラクチャの管理を意識する必要はない。

#### 2.7 柔軟な構成

Outposts は、様々なサイズや構成のモデルを提供しており、ユーザーのニーズに合わせて選択できる。  
これにより、必要なリソースを柔軟に利用できる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、AWS のハードウェアをオンプレミス環境に設置。
2. Outposts は、AWS のリージョンに接続され、コントロールプレーンやデータプレーンを共有。
3. EC2 インスタンス、EBS ボリュームなどのリソースは、Outposts 上でローカルに実行。
4. ユーザーは、AWS の API、ツール、およびコンソールを使用して、Outposts 上のリソースを管理。
5. 必要に応じて、オンプレミス環境と AWS クラウド環境の間でデータ連携。

AWS Outposts は、AWS のグローバルインフラストラクチャの一部であり、オンプレミス環境に AWS クラウドの機能を提供する。  
Outposts のハードウェア管理は AWS が行うため、ユーザーはインフラの管理を行う必要はない。

### 4. セキュリティと認証・認可

AWS Outposts は、AWS のセキュリティモデルに準拠しており、リソースのセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、Outposts へのアクセスを制御する。
- **VPC**: Virtual Private Cloud (VPC) を利用して、Outposts 内のリソースをネットワーク的に隔離。
- **セキュリティグループ**: ネットワークアクセスをセキュリティグループで制御。
- **データ暗号化**: データは転送中および保存時に暗号化される。
- **アクセス制御**: IAM ポリシーを通じて、ユーザーやグループごとに、Outposts のリソース操作権限を詳細に制御できる。

これらのセキュリティ対策により、Outposts 内のリソースとそのデータを安全に保護する。

### 5. 料金形態

AWS Outposts の料金は主に以下に基づきる:

- **Outposts のモデル**: Outposts のハードウェア構成（ラックのサイズ、CPU、メモリ、ストレージなど）によって料金が異なりる。
- **AWS サービスの利用料**: Outposts 上で利用する EC2、EBS、RDS などの AWS サービスの利用料金が発生。
- **データ転送**: Outposts 内外へのデータ転送量に応じて課金。
- **導入サポート**: Outposts の導入、設置、保守に関する料金が発生する場合がある。

### 6. よくあるアーキテクチャ・設計パターン

AWS Outposts は、様々なオンプレミス環境でのワークロードに利用できる。  
一般的なパターンは以下の通りである:

- **ローカルデータ処理**: 大量のデータをオンプレミスでローカルに処理し、クラウドへのデータ転送に伴う遅延やコストを削減。
- **低レイテンシーアプリケーションの実行**: リアルタイムアプリケーションやインタラクティブアプリケーションをオンプレミス環境で実行し、低レイテンシーを実現。
- **データ所在地の要件を満たすアプリケーション**: データが特定の場所から移動できないという規制要件を満たすために、データをオンプレミスで処理。
- **ハイブリッドクラウド環境の構築**: オンプレミス環境と AWS クラウド環境を連携させ、アプリケーションを柔軟に配置。
- **データ分析処理**: 大量のデータをオンプレミスで分析し、洞察を得る。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS アカウントを作成し、Outposts の注文リクエストを送信。
2. AWS が Outposts ハードウェアをオンプレミス環境に設置。
3. VPC を拡張し、Outposts にサブネットを作成。
4. EC2 インスタンス、EBS ボリュームなどのリソースを Outposts にデプロイ。
5. アプリケーションをデプロイし、Outposts 上で実行。
6. 必要に応じて、オンプレミス環境と AWS クラウド環境を接続。

### 8. 試験で問われやすいポイント

#### 8.1 オンプレミスへの AWS 拡張

- **機能**: AWS のインフラストラクチャ、サービス、API、ツールをオンプレミス環境に拡張。
- **利点**: AWS クラウドと同じ環境をオンプレミスで利用可能。
- **試験対策**: オンプレミスへの拡張のメリット、利用シナリオが問われる。

#### 8.2 ローカルデータ処理

- **機能**: データをオンプレミス環境でローカルに処理。
- **目的**: クラウドへのデータ転送に伴うレイテンシーや帯域幅の制約を回避。
- **試験対策**: ローカルデータ処理のメリット、利用ケースが問われる。

#### 8.3 低レイテンシーアプリケーションの実行

- **利点**: エンドユーザーに近い場所でアプリケーションを実行。
- **効果**: リアルタイムアプリケーションやインタラクティブアプリケーションの応答時間を短縮。
- **試験対策**: 低レイテンシーの重要性、ユースケースが問われる。

#### 8.4 ハイブリッドクラウド環境

- **機能**: オンプレミス環境と AWS クラウド環境をシームレスに連携。
- **利用**: アプリケーションを柔軟に配置、最適なリソース利用。
- **試験対策**: ハイブリッドクラウドのメリット、連携方法が問われる。

#### 8.5 AWS サービスとの統合

- **統合対象**: EC2, EBS, VPC, RDS, ECS, EKS, Lambda など。
- **利用**: AWS クラウドと同じように、アプリケーションを開発、デプロイ。
- **試験対策**: 連携できるサービス、利用方法が問われる。

#### 8.6 フルマネージドサービス

- **対象**: ハードウェアの管理、メンテナンス。
- **管理主体**: AWS が担当。
- **試験対策**: フルマネージドのメリット、管理範囲が問われる。

#### 8.7 料金体系

- **課金対象**: Outposts のモデル、AWS サービスの利用料、データ転送量、導入サポートなど。
- **最適化**: 必要なリソースを適切に選択し、データ転送量を最適化。
- **試験対策**: 料金体系、課金対象が問われる。

#### 8.8 類似・関連サービスとの比較

- **AWS Local Zones**: 特定の都市や地域で低レイテンシーを提供。Outposts はオンプレミス環境に AWS を拡張。
- **AWS Snowball Edge**: 大量のデータを AWS に移行するためのデバイス。Outposts は AWS のインフラストラクチャをオンプレミスに配置。

#### 8.9 試験で頻出となる具体的な問われ方と答え

- Q: AWS Outposts は何を提供するサービスか？
  - A: AWS のインフラストラクチャ、サービス、API、およびツールをオンプレミス環境に拡張するサービスである。
- Q: AWS Outposts を利用することで、どのようなメリットが得られるか？
  - A: オンプレミス環境で必要な低レイテンシー、ローカルデータ処理、データ所在地の要件を満たしつつ、AWS の利点を活用できる。
- Q: AWS Outposts で利用できる AWS サービスは何か？
  - A: EC2、EBS、VPC、RDS、ECS、EKS、Lambda など、様々な AWS サービスと統合できる。
- Q: AWS Outposts のハードウェアの管理は誰が行いるか？
  - A: AWS が行いる。
- Q: AWS Outposts の料金はどのように計算されるか？
  - A: Outposts のモデル、AWS サービスの利用料、データ転送量、導入サポートなどに基づいて計算される。

---

## AWS Serverless Application Repository

### 1. サービス概要

AWS Serverless Application Repository は、AWS が提供するフルマネージドサービスで、サーバーレスアプリケーションを共有、検索、デプロイするためのリポジトリである。  
このサービスを利用することで、開発者は AWS Lambda 関数、API Gateway、DynamoDB テーブル、その他のサーバーレスリソースをパッケージ化し、共有できる。  
また、他の開発者が公開したサーバーレスアプリケーションを検索し、簡単にデプロイできる。

主なユースケースとして、

- 組織内でのサーバーレスコンポーネントの共有
- 再利用可能なサーバーレスアプリケーションの公開
- コミュニティでのサーバーレスソリューションの共有

などが挙げられる。

### 2. 主な特徴と機能

#### 2.1 サーバーレスアプリケーションの共有

Serverless Application Repository は、サーバーレスアプリケーションをパッケージ化し、他のユーザーと共有できる機能を提供する。  
これにより、組織内やコミュニティで再利用可能なサーバーレスコンポーネントを共有できる。

#### 2.2 検索可能なリポジトリ

Serverless Application Repository は、公開されているサーバーレスアプリケーションを検索できる。  
キーワード、カテゴリ、発行者などでフィルタリングできる。

#### 2.3 簡単なデプロイ

Serverless Application Repository に公開されたアプリケーションを、AWS コンソールや AWS CLI を使用して簡単にデプロイできる。  
これにより、サーバーレスアプリケーションのデプロイプロセスを簡素化できる。

#### 2.4 バージョン管理

サーバーレスアプリケーションのバージョン管理をサポートしている。  
これにより、異なるバージョンのアプリケーションを管理し、必要に応じて以前のバージョンにロールバックできる。

#### 2.5 SAM (Serverless Application Model) のサポート

AWS Serverless Application Model (SAM) を使用して定義されたサーバーレスアプリケーションをサポートしている。  
これにより、SAM テンプレートを使用して、サーバーレスアプリケーションを簡単にパッケージ化し、デプロイできる。

#### 2.6 アクセス制御

AWS IAM を利用して、Serverless Application Repository へのアクセスを制御し、権限を管理できる。  
これにより、アプリケーションの公開やデプロイを特定のユーザーやグループに制限できる。

#### 2.7 セキュリティ

Serverless Application Repository は、アプリケーションの暗号化、アクセス制御に対応し、安全なサーバーレスアプリケーションの共有を保証する。  
IAM によるアクセス制御、保存中のデータを暗号化をサポートしている。

- **IAM 連携**: AWS IAM を使用してアクセス制御と権限管理。
- **データ暗号化**: 保存中のデータを暗号化。

#### 2.8 統合性

Serverless Application Repository は、AWS の他のサービス（AWS Lambda, AWS SAM, AWS CloudFormation など）と統合されており、サーバーレスアプリケーションの開発、デプロイ、管理を効率的に行える。  
AWS Serverless Application Model (SAM) を利用して、簡単にアプリケーションを公開できる。

### 3. アーキテクチャおよび技術要素

1. 開発者は、AWS SAM または AWS コンソールを使用して、サーバーレスアプリケーションをパッケージ化。
2. パッケージ化されたアプリケーションを、Serverless Application Repository に公開。
3. 他の開発者は、Serverless Application Repository を検索し、必要なアプリケーションを特定。
4. アプリケーションを AWS コンソールまたは AWS CLI からデプロイ。

Serverless Application Repository は、サーバーレスアプリケーションの共有、検索、デプロイを効率化するフルマネージドサービスである。  
アプリケーションの再利用を促進し、開発プロセスを迅速化する。

### 4. セキュリティと認証・認可

セキュリティは Serverless Application Repository の重要な要素である:

- **IAM によるアクセス制御**: AWS IAM を利用して、リポジトリへのアクセスを制御し、権限を管理。
- **データ暗号化**: 保存中のアプリケーションを暗号化し、データの機密性を保護。
- **監査ログ**: AWS CloudTrail を利用して、API 呼び出しやリソース変更を記録。

これにより、アプリケーションの安全な共有と利用を確保できる。

### 5. 料金形態

AWS Serverless Application Repository 自体の利用に料金はかかりない。  
ただし、リポジトリに公開されたアプリケーションで使用される AWS サービス（Lambda 関数、API Gateway など）の利用料金が発生する。

- **アプリケーションデプロイ**: アプリケーションが使用する AWS サービスの使用量に応じた課金。

### 6. よくあるアーキテクチャ・設計パターン

一般的なパターンは以下の通りである:

- **組織内でのサーバーレスコンポーネントの共有**: 組織内で再利用可能な Lambda 関数や API Gateway を Serverless Application Repository で共有。
- **再利用可能なサーバーレスアプリケーションの公開**: 一般的なサーバーレスアプリケーションを公開し、他の開発者が簡単にデプロイできるようにする。
- **コミュニティでのサーバーレスソリューションの共有**: オープンソースのサーバーレスソリューションを公開し、コミュニティで共有、改善。
- **マイクロサービスのデプロイ**: マイクロサービスをサーバーレスアプリケーションとして定義し、Serverless Application Repository で共有。
- **API の共有**: API Gateway を介して公開された API を、Serverless Application Repository で共有し、再利用性を高める。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS SAM または AWS コンソールを使用して、サーバーレスアプリケーションをパッケージ化。
2. Serverless Application Repository にアプリケーションを公開。
3. 他の AWS アカウントから公開されたアプリケーションを検索。
4. アプリケーションをデプロイし、設定をカスタマイズ。
5. デプロイされたアプリケーションの動作を確認。

### 8. 試験で問われやすいポイント

#### 8.1 サーバーレスアプリケーションの共有

- **パッケージ化**: サーバーレスアプリケーションをパッケージ化して共有できることを理解。
- **再利用性**: 再利用可能なサーバーレスコンポーネントを共有できることを理解。

#### 8.2 検索可能なリポジトリ

- **アプリケーション検索**: 公開されたアプリケーションを検索できることを理解。
- **検索フィルタ**: キーワード、カテゴリ、発行者などでフィルタリングできることを理解。

#### 8.3 簡単なデプロイ

- **デプロイ手順**: アプリケーションを簡単にデプロイできることを理解。
- **プロセス簡素化**: サーバーレスアプリケーションのデプロイプロセスを簡素化できることを理解。

#### 8.4 料金体系

- **サービス利用料金**: Serverless Application Repository 自体の利用は無料であることを理解。
- **関連サービス料金**: アプリケーションで使用される Lambda などの AWS サービスの利用料金が発生することを理解。

#### 8.5 類似・関連サービスとの比較

- **AWS CodeArtifact**: パッケージ管理サービス。Serverless Application Repository はサーバーレスアプリケーションに特化。
- **AWS CloudFormation Registry**: リソースタイプの登録と管理。Serverless Application Repository はアプリケーションの共有に特化。

#### 8.6 試験で頻出となる具体的な問われ方と答え

- Q: AWS Serverless Application Repository の主な用途は？
  - A: サーバーレスアプリケーションの共有、検索、デプロイを容易にすること。
- Q: Serverless Application Repository で共有できるのは？
  - A: AWS Lambda 関数、API Gateway、DynamoDB テーブルなどサーバーレスリソース。
- Q: Serverless Application Repository でアプリケーションを検索する方法は？
  - A: キーワード、カテゴリ、発行者など。
- Q: Serverless Application Repository でサポートするテンプレートは？
  - A: AWS Serverless Application Model (SAM)。
- Q: Serverless Application Repository のセキュリティ対策は？
  - A: IAM によるアクセス制御、保存時のデータ暗号化など。
- Q: Serverless Application Repository 自体の利用料金は？
  - A: 無料。
- Q: Serverless Application Repository と CodeArtifact の違いは？
  - A: CodeArtifact はパッケージ管理、Serverless Application Repository はサーバーレスアプリケーション共有に特化。

---

## AWS Wavelength

### 1. サービス概要

AWS Wavelength は、5G ネットワークのエッジに AWS のコンピューティングおよびストレージサービスを組み込むことで、超低レイテンシーを必要とするアプリケーションをモバイルデバイスやエンドユーザーの近くで実行できるようにするサービスである。  
ユーザーは、通信事業者の 5G ネットワークのエッジで、EC2 インスタンス、EBS ボリューム、VPC などの AWS サービスを利用し、データ処理を高速化し、応答時間を短縮できる。  
これにより、モバイルデバイスやエンドユーザーのエクスペリエンスを向上させ、新しいアプリケーションの可能性を広げることができる。

主なユースケースとして、

- リアルタイムゲーム
- AR/VR アプリケーション
- 機械学習推論
- 自動運転
- スマートシティ
- コネクテッドカー
- 産業オートメーション

などが挙げられる。  
AWS Wavelength は、これらのユースケースに対応するための様々な機能と、AWS の他のサービスとの統合を提供する。

### 2. 主な特徴と機能

#### 2.1 5G エッジコンピューティング

Wavelength は、通信事業者の 5G ネットワークのエッジに AWS のコンピューティングおよびストレージサービスを配置する。  
これにより、モバイルデバイスやエンドユーザーに近い場所でアプリケーションを実行し、超低レイテンシーを実現する。

#### 2.2 低レイテンシー接続

Wavelength は、5G ネットワークのエッジと AWS リージョンを高速かつ低レイテンシーで接続する。  
これにより、オンプレミス環境や AWS クラウドとの連携をスムーズに行うことができる。

#### 2.3 既存の AWS サービスとの連携

Wavelength は、EC2, EBS, VPC, ECS, EKS など、既存の AWS サービスとシームレスに連携する。  
ユーザーは、これらのサービスを Wavelength で利用し、アプリケーションを簡単に展開できる。

#### 2.4 スケーラビリティ

Wavelength は、アプリケーションの需要に応じて、リソースを柔軟にスケーリングできる。  
これにより、トラフィックの変動に対応し、安定したアプリケーションパフォーマンスを提供できる。

#### 2.5 柔軟なネットワーク構成

VPC を利用して、Wavelength Zone 内のリソースをネットワーク的に隔離できる。  
また、AWS Direct Connect を通じて、オンプレミス環境と Wavelength Zone を接続することも可能である。

#### 2.6 アクセス制御

IAM ポリシーを使用して、Wavelength Zone へのアクセスを制御できる。  
特定のユーザーやグループに対して、リソースの作成、変更、削除などの権限を付与できる。

#### 2.7 統合性と拡張性

AWS Wavelength は、AWS の他のサービスと密接に統合されており、アプリケーション開発を効率的に行える。  
また、API を利用して、Wavelength のリソース管理を自動化することもできる。

### 3. アーキテクチャおよび技術要素

1. ユーザーは、VPC を拡張して、Wavelength Zone にサブネットを作成。
2. EC2 インスタンス、EBS ボリュームなどのリソースを Wavelength Zone にデプロイ。
3. アプリケーションは Wavelength Zone 内で実行され、5G ネットワーク経由でモバイルデバイスやエンドユーザーに低レイテンシーでサービスを提供。
4. Wavelength Zone は、AWS リージョンと接続し、コントロールプレーンやデータプレーンを共有。
5. 必要に応じて、Direct Connect でオンプレミス環境と接続。

AWS Wavelength は、AWS のグローバルインフラストラクチャの一部であり、5G ネットワークのエッジに AWS の機能を拡張する。  
Wavelength のリソース管理は AWS が行うため、ユーザーはインフラの管理を行う必要はない。

### 4. セキュリティと認証・認可

AWS Wavelength は、AWS のセキュリティモデルに準拠しており、リソースのセキュリティを確保するために、以下の機能を提供する:

- **IAM 統合**: AWS Identity and Access Management (IAM) を利用して、Wavelength Zone へのアクセスを制御する。
- **VPC**: Virtual Private Cloud (VPC) を利用して、Wavelength Zone 内のリソースをネットワーク的に隔離。
- **セキュリティグループ**: ネットワークアクセスをセキュリティグループで制御。
- **データ暗号化**: データは転送中および保存時に暗号化される。
- **アクセス制御**: IAM ポリシーを通じて、ユーザーやグループごとに、Wavelength Zone のリソース操作権限を詳細に制御できる。

これらのセキュリティ対策により、Wavelength Zone 内のリソースとそのデータを安全に保護する。

### 5. 料金形態

AWS Wavelength の料金は主に以下に基づきる:

- **EC2 インスタンス**: Wavelength Zone で実行する EC2 インスタンスの利用料金。
- **EBS ボリューム**: Wavelength Zone で使用する EBS ボリュームの利用料金。
- **データ転送**: Wavelength Zone 内外へのデータ転送量に応じて課金。
- **Wavelength Zone への接続**: Wavelength Zone への接続に関する料金。

### 6. よくあるアーキテクチャ・設計パターン

AWS Wavelength は、様々な低レイテンシーアプリケーションのデプロイメントに利用できる。  
一般的なパターンは以下の通りである:

- **リアルタイムゲーム**: モバイルゲームのゲームサーバーを Wavelength Zone で実行し、プレイヤーに低レイテンシーなゲーム体験を提供。
- **AR/VR アプリケーション**: AR/VR アプリケーションのレンダリングや処理を Wavelength Zone で実行し、リアルタイムなインタラクションを実現。
- **機械学習推論**: 機械学習モデルの推論処理を Wavelength Zone で実行し、モバイルデバイスや IoT デバイスへのリアルタイムな推論結果を提供。
- **自動運転**: 自動運転車のセンサーデータ処理や制御ロジックを Wavelength Zone で実行し、安全な運転をサポート。
- **スマートシティ**: スマートシティのセンサーデータ処理や分析を Wavelength Zone で実行し、都市の管理を効率化。
- **コネクテッドカー**: コネクテッドカーのデータ処理やアプリケーションを Wavelength Zone で実行し、低レイテンシーなサービスを提供。
- **産業オートメーション**: 産業オートメーションシステムの制御やデータ処理を Wavelength Zone で実行し、リアルタイムな制御を実現。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS マネジメントコンソールから AWS Wavelength を開き、利用する Wavelength Zone を有効化。
2. VPC を拡張し、Wavelength Zone にサブネットを作成。
3. Wavelength Zone に EC2 インスタンス、EBS ボリュームなどのリソースをデプロイ。
4. アプリケーションをデプロイし、Wavelength Zone で実行。
5. 必要に応じて、ロードバランサーを設定し、トラフィックを分散。
6. モバイルデバイスやエンドユーザーからアプリケーションにアクセスし、低レイテンシーでの動作を確認。

### 8. 試験で問われやすいポイント

#### 8.1 5G エッジコンピューティング

- **特徴**: 5G ネットワークのエッジに AWS サービスを配置。
- **目的**: モバイルデバイスやエンドユーザーに近い場所でアプリケーションを実行し、超低レイテンシーを実現。
- **試験対策**: 5G エッジコンピューティングの重要性、Wavelength の利用ケースが問われる。

#### 8.2 低レイテンシー接続

- **特徴**: 5G ネットワークのエッジと AWS リージョンを高速かつ低レイテンシーで接続。
- **利用**: オンプレミス環境や AWS クラウドとの連携。
- **試験対策**: 低レイテンシー接続の重要性、メリットが問われる。

#### 8.3 既存の AWS サービスとの連携

- **連携対象**: EC2, EBS, VPC, ECS, EKS など。
- **利点**: 既存の AWS サービスを Wavelength で利用可能。
- **試験対策**: 連携できるサービス、利用方法が問われる。

#### 8.4 スケーラビリティ

- **機能**: アプリケーションの需要に応じてリソースを柔軟にスケーリング。
- **目的**: トラフィック変動に対応し、安定したパフォーマンスを提供。
- **試験対策**: スケーラビリティの仕組み、メリットが問われる。

#### 8.5 柔軟なネットワーク構成

- **利用技術**: VPC を利用して、リソースをネットワーク的に隔離。
- **接続**: Direct Connect でオンプレミス環境と接続。
- **試験対策**: ネットワーク構成、接続方法が問われる。

#### 8.6 アクセス制御

- **利用サービス**: IAM ポリシー。
- **目的**: Wavelength Zone へのアクセスを制御。
- **試験対策**: IAM ポリシーの設定方法、権限制御が問われる。

#### 8.7 料金体系

- **課金対象**: EC2 インスタンス、EBS ボリューム、データ転送量、Wavelength Zone への接続。
- **最適化**: リソース使用量の最適化、データ転送量の削減がコスト最適化に有効。
- **試験対策**: 料金体系、課金対象が問われる。

#### 8.8 類似・関連サービスとの比較

- **AWS Local Zones**: 特定の都市や地域で低レイテンシーを提供。Wavelength は 5G ネットワークのエッジに特化。
- **AWS Outposts**: オンプレミス環境に AWS インフラストラクチャを拡張。Wavelength は通信事業者のネットワークエッジに AWS を拡張。

#### 8.9 試験で頻出となる具体的な問われ方と答え

- Q: AWS Wavelength は何を提供するサービスか？
  - A: 5G ネットワークのエッジに AWS のコンピューティングおよびストレージサービスを組み込むことで、超低レイテンシーを必要とするアプリケーションを実行できるようにするサービスである。
- Q: AWS Wavelength は、どのような場所でサービスを提供するか？
  - A: 通信事業者の 5G ネットワークのエッジでサービスを提供する。
- Q: AWS Wavelength を利用することで、どのようなメリットが得られるか？
  - A: モバイルデバイスやエンドユーザーに近い場所でアプリケーションを実行し、超低レイテンシーを実現できる。
- Q: AWS Wavelength で利用できる AWS サービスは何か？
  - A: EC2、EBS、VPC、ECS、EKS など、既存の AWS サービスと連携できる。
- Q: AWS Wavelength の料金はどのように計算されるか？
  - A: EC2 インスタンス、EBS ボリューム、データ転送量、Wavelength Zone への接続などに基づいて計算される。

---

## VMware Cloud on AWS

### 1. サービス概要

VMware Cloud on AWS は、AWS が提供するサービスで、AWS クラウド上で VMware のソフトウェア定義データセンター (SDDC) を実行できるハイブリッドクラウドソリューションである。  
このサービスを利用することで、既存のオンプレミス VMware 環境を AWS に拡張し、アプリケーションの移行、拡張、保護を容易に行うことができる。  
VMware Cloud on AWS は、VMware vSphere, vSAN, NSX, vCenter Server といった VMware の主要コンポーネントで構成されている。

主なユースケースとして、

- オンプレミス環境からのクラウド移行
- 災害復旧
- アプリケーションの拡張
- ハイブリッドクラウド環境の構築
- データセンターの統合

などが挙げられる。

### 2. 主な特徴と機能

#### 2.1 VMware SDDC on AWS

VMware Cloud on AWS は、AWS 上で VMware のソフトウェア定義データセンター (SDDC) を実行できる唯一のサービスである。  
これにより、既存の VMware 環境との互換性を維持しながら、AWS の柔軟性とスケーラビリティを活用できる。

#### 2.2 ハイブリッドクラウド環境

オンプレミス VMware 環境と AWS 上の VMware Cloud on AWS をシームレスに接続し、ハイブリッドクラウド環境を構築できる。  
これにより、アプリケーションの移行やデータ転送を容易に行える。

#### 2.3 既存の VMware スキルの活用

VMware vSphere, vSAN, NSX, vCenter Server などの既存の VMware スキルをそのまま活用できる。  
新しい技術を習得する必要がなく、運用管理を効率的に行える。

#### 2.4 柔軟なリソーススケーリング

vSphere クラスタ内のホスト数を柔軟に増減できる。  
これにより、リソース需要の変化に対応し、必要なリソースだけを効率的に利用できる。

#### 2.5 災害復旧 (DR)

オンプレミス VMware 環境の災害復旧先として、VMware Cloud on AWS を利用できる。  
これにより、事業継続性を確保できる。

#### 2.6 幅広い AWS サービスとの統合

VMware Cloud on AWS は、Amazon S3, Amazon RDS, Amazon DynamoDB, AWS Lambda など、様々な AWS サービスと統合できる。  
これにより、AWS の豊富なサービスを活用したハイブリッドアプリケーションを構築できる。

#### 2.7 セキュリティ

VMware Cloud on AWS は、VMware のセキュリティ機能と AWS のセキュリティ機能を組み合わせ、安全なハイブリッドクラウド環境を構築する。  
AWS IAM によるアクセス制御、データ暗号化、VPC 内でのプライベート接続をサポートしている。

- **IAM 連携**: AWS IAM を使用してアクセス制御と権限管理。
- **データ暗号化**: 転送中および保存中のデータを暗号化。
- **VPC サポート**: Amazon VPC 内でのプライベート接続。

#### 2.8 統合性

VMware Cloud on AWS は、VMware vCenter Server、AWS Management Console、AWS CLI など、様々な管理ツールと統合されており、環境の監視、設定、管理を効率的に行うことができる。  
AWS Direct Connect と連携して、オンプレミス環境から高速かつ安全な接続を確立できる。

### 3. アーキテクチャおよび技術要素

1. VMware SDDC は、AWS のベアメタルサーバー上に展開。
2. vSphere、vSAN、NSX、vCenter Server などの VMware コンポーネントで構成。
3. オンプレミス VMware 環境と AWS 上の VMware SDDC は、AWS Direct Connect または VPN で接続。
4. AWS サービスは、VPC エンドポイントまたは Direct Connect 経由で、VMware SDDC にアクセス。

VMware Cloud on AWS は、AWS のインフラストラクチャ上に VMware SDDC を構築し、ハイブリッドクラウド環境をサポートする。  
既存の VMware 環境を AWS に拡張し、シームレスな運用を実現する。

### 4. セキュリティと認証・認可

セキュリティは VMware Cloud on AWS の重要な要素である:

- **IAM によるアクセス制御**: AWS IAM を利用して、VMware Cloud on AWS リソースへのアクセスを制御し、権限を管理。
- **データ暗号化**: 転送中および保存中のデータを暗号化し、データの機密性を保護。
- **VPC サポート**: Amazon VPC 内で VMware Cloud on AWS を使用する場合、プライベート接続を確立。
- **VMware セキュリティ機能**: VMware NSX によるマイクロセグメンテーションなどを利用。
- **監査ログ**: AWS CloudTrail を利用して、API 呼び出しやリソース変更を記録。

これにより、データの安全性とコンプライアンスを確保できる。

### 5. 料金形態

VMware Cloud on AWS の料金は主に以下に基づきる:

- **ホスト時間**: VMware SDDC で使用するホストの実行時間に応じた課金。
- **ストレージ**: VMware vSAN で使用するストレージ量に応じた課金。
- **ネットワーク**: データ転送量に応じた課金。
- **ソフトウェアライセンス**: VMware ソフトウェアライセンスの利用料金。

### 6. よくあるアーキテクチャ・設計パターン

一般的なパターンは以下の通りである:

- **オンプレミス環境からのクラウド移行**: 既存のオンプレミス VMware 環境を AWS に移行し、クラウドのメリットを享受。
- **災害復旧**: オンプレミス VMware 環境の災害復旧先として、VMware Cloud on AWS を利用し、事業継続性を確保。
- **アプリケーションの拡張**: オンプレミスのリソースが不足した場合に、VMware Cloud on AWS のリソースを利用してアプリケーションを拡張。
- **ハイブリッドクラウド環境の構築**: オンプレミスと AWS の両方にまたがるアプリケーションをシームレスに連携させるハイブリッドクラウド環境を構築。
- **データセンターの統合**: 複数のオンプレミスデータセンターを VMware Cloud on AWS に統合し、運用管理を効率化。

### 7. 設定・デプロイ手順（ハンズオン例）

1. AWS コンソールで VMware Cloud on AWS の SDDC を作成。
2. オンプレミス VMware 環境と VMware Cloud on AWS の接続を構成。
3. VMware vCenter Server を使用して、VMware Cloud on AWS の仮想マシンを管理。
4. AWS サービスと VMware SDDC の連携を構成。
5. VMware Cloud on AWS のパフォーマンスとセキュリティを監視。

### 8. 試験で問われやすいポイント

#### 8.1 VMware SDDC on AWS

- **VMware SDDC**: AWS 上で VMware のソフトウェア定義データセンターを実行できることを理解。
- **互換性維持**: 既存の VMware 環境との互換性を維持できることを理解。

#### 8.2 ハイブリッドクラウド環境

- **シームレスな接続**: オンプレミス VMware 環境と AWS 上の VMware Cloud on AWS をシームレスに接続できることを理解。
- **アプリケーション移行**: アプリケーションの移行やデータ転送が容易になることを理解。

#### 8.3 既存の VMware スキル

- **スキル活用**: vSphere, vSAN, NSX, vCenter Server などの既存の VMware スキルをそのまま活用できることを理解。
- **運用効率化**: 新しい技術を習得する必要がなく、運用管理を効率的に行えることを理解。

#### 8.4 料金体系

- **ホスト時間**: ホストの実行時間に応じた課金を理解。
- **ストレージ**: VMware vSAN で使用するストレージ量に応じた課金を理解。
- **ネットワーク**: データ転送量に応じた課金を理解。
- **ソフトウェアライセンス**: VMware ソフトウェアライセンスの利用料金が発生することを理解。

#### 8.5 類似・関連サービスとの比較

- **AWS Outposts**: AWS のインフラストラクチャをオンプレミス環境に拡張するサービス。VMware Cloud on AWS は VMware 環境を AWS に拡張。
- **Amazon EC2**: AWS の仮想サーバーサービス。VMware Cloud on AWS は VMware 環境を AWS に提供。

#### 8.6 試験で頻出となる具体的な問われ方と答え

- Q: VMware Cloud on AWS の主な用途は？
  - A: VMware 環境を AWS に拡張し、ハイブリッドクラウド環境を構築すること。
- Q: VMware Cloud on AWS で利用できる VMware コンポーネントは？
  - A: vSphere, vSAN, NSX, vCenter Server。
- Q: VMware Cloud on AWS で既存のスキルを活用できる？
  - A: はい、既存の VMware スキルをそのまま活用可能。
- Q: VMware Cloud on AWS はどのような環境とシームレスに接続できる？
  - A: オンプレミス VMware 環境。
- Q: VMware Cloud on AWS のセキュリティ対策は？
  - A: IAM によるアクセス制御、データ暗号化、VPC サポートなど。
- Q: VMware Cloud on AWS の料金体系は？
  - A: ホスト時間、ストレージ、ネットワーク、ソフトウェアライセンスに基づいた課金。
- Q: VMware Cloud on AWS と AWS Outposts の違いは？
  - A: Outposts は AWS のインフラをオンプレミスに拡張、VMware Cloud on AWS は VMware 環境を AWS に拡張。
